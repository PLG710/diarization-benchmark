{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b951ed03",
   "metadata": {},
   "source": [
    "Pipeline A: Whisper -> LLM-Diarisierung\n",
    "Kein Chunking, kein JSON\n",
    "Output: [Sprecher 1]: ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba28719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports + Konfiguration\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# .env-Variablen (nicht öffentlich) laden\n",
    "VLLM_BASE_URL = os.getenv(\"VLLM_BASE_URL\")\n",
    "VLLM_MODEL = os.getenv(\"VLLM_MODEL\")\n",
    "REPO_ROOT = Path((os.getenv(\"REPO_ROOT\"))).expanduser().resolve()\n",
    "TEST_AUDIO = REPO_ROOT / os.getenv(\"TEST_AUDIO\") # In .env definierte Audio-Datei für einzelne Tests\n",
    "\n",
    "# Pfad zu gespeicherten Audios\n",
    "AUDIO_DIR = REPO_ROOT / \"data\" / \"input_audio\"\n",
    "CONVERTED_DIR = REPO_ROOT / \"data\" / \"normalised_audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7d5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Audio-Normalisierung via ffmpeg, alles konvertieren zu WAV 16khz Mono -> Wichtig für Pyannote\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def ensure_wav_16k_mono(input_path: str | Path, out_dir: str | Path) -> Path:\n",
    "    input_path = Path(input_path)\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    out_path = out_dir / f\"{input_path.stem}_16k_mono.wav\"\n",
    "\n",
    "    # Reuse, wenn schon vorhanden\n",
    "    if out_path.exists() and out_path.stat().st_size > 0:\n",
    "        return out_path\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-i\", str(input_path),\n",
    "        \"-ac\", \"1\",        # mono\n",
    "        \"-ar\", \"16000\",    # 16kHz\n",
    "        \"-vn\",             # no video\n",
    "        str(out_path),\n",
    "    ]\n",
    "    res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if res.returncode != 0:\n",
    "        raise RuntimeError(f\"ffmpeg failed:\\n{res.stderr}\")\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b1faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Konvertierungs-Test\n",
    "# Testaudio mit normalisierter Version überschreiben\n",
    "conversion_test = False\n",
    "if conversion_test:\n",
    "    TEST_AUDIO = ensure_wav_16k_mono(TEST_AUDIO, CONVERTED_DIR)\n",
    "\n",
    "    print(\"WAV:\", TEST_AUDIO)\n",
    "    print(\"Exists:\", TEST_AUDIO.exists(), \"Size:\", TEST_AUDIO.stat().st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20b9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "### vLLM-client\n",
    "\n",
    "def chat_vllm(messages, model=VLLM_MODEL, temperature=0.0, max_tokens=200, timeout=600):\n",
    "    url = f\"{VLLM_BASE_URL}/chat/completions\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "    }\n",
    "    r = requests.post(url, json=payload, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    content = data[\"choices\"][0][\"message\"].get(\"content\", None)\n",
    "    if content is None:\n",
    "        raise RuntimeError(f\"LLM returned no content. Full response: {json.dumps(data)[:2000]}\")\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c076cc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kurzer LLM-Test: Bei Bedarf auf True setzen\n",
    "llm_test = True\n",
    "\n",
    "if llm_test:\n",
    "    print(chat_vllm([{\"role\":\"user\",\"content\":\"Antworte nur mit OK\"}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147f205",
   "metadata": {},
   "source": [
    "Whisper-Transkription der Audio via faster-whisper\n",
    "- lokal reproduzierbar, keine Cloud\n",
    "- wir nehmen Segment-Zeitstempel für späteren Pyannote-Merge (nicht benötigt für LLM-Diarisierung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e6bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code für Transkription\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "WHISPER_MODEL_SIZE = os.getenv(\"WHISPER_MODEL_SIZE\", \"small\") # Kleines Modell für Tests\n",
    "# WHISPER_MODEL_SIZE = os.getenv(\"WHISPER_MODEL_SIZE\", \"large-v3\") # Großes Modell für Prod\n",
    "WHISPER_DEVICE = os.getenv(\"WHISPER_DEVICE\", \"cpu\")  # Für unseren Test auf CPU laufen lassen -> langsamer\n",
    "# WHISPER_DEVICE = os.getenv(\"WHISPER_DEVICE\", \"cuda\") # Wenn verfügbar: Auf GPU laufen lassen -> schneller -> Aber: Konfig-Anpassungen notwendig!\n",
    "WHISPER_COMPUTE_TYPE = os.getenv(\"WHISPER_COMPUTE_TYPE\", \"int8\")  # cpu: int8 gut\n",
    "\n",
    "_whisper_model = None\n",
    "\n",
    "def get_whisper_model():\n",
    "    global _whisper_model\n",
    "    if _whisper_model is None:\n",
    "        _whisper_model = WhisperModel(\n",
    "            WHISPER_MODEL_SIZE,\n",
    "            device=WHISPER_DEVICE,\n",
    "            compute_type=WHISPER_COMPUTE_TYPE,\n",
    "        )\n",
    "    return _whisper_model\n",
    "\n",
    "def transcribe_faster_whisper(audio_path: str, language: str | None = None):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      transcript: str (full text)\n",
    "      segments: list of dicts: [{\"start\": float, \"end\": float, \"text\": str}, ...]\n",
    "    \"\"\"\n",
    "    model = get_whisper_model()\n",
    "    segments_iter, info = model.transcribe(\n",
    "        audio_path,\n",
    "        language=language,\n",
    "        vad_filter=True,\n",
    "        word_timestamps=False,  # später ggf. True, falls wir word-level brauchen\n",
    "    )\n",
    "    segments = []\n",
    "    texts = []\n",
    "    for seg in segments_iter:\n",
    "        txt = seg.text.strip()\n",
    "        segments.append({\"start\": float(seg.start), \"end\": float(seg.end), \"text\": txt})\n",
    "        texts.append(txt)\n",
    "    transcript = \"\\n\".join(texts).strip()\n",
    "    return transcript, segments, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ccf199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper-Test anhand der Test-Audio. Aktivieren -> True setzen\n",
    "whisper_test = False\n",
    "if whisper_test:\n",
    "    t, segs, info = transcribe_faster_whisper(TEST_AUDIO, language=\"de\")\n",
    "    print(\"Language:\", info.language, \"Prob:\", info.language_probability)\n",
    "    print(\"Transcript:\\n\", t[:1000])\n",
    "    print(\"\\nFirst segments:\", segs[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80cb3cc",
   "metadata": {},
   "source": [
    "### LLM-Diarisierung Prompt\n",
    "System- und User-Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f206fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diarize_with_llm(transcript: str):\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a professional conversation diarization engine. \"\n",
    "        \"Assign speaker labels logically solely based on the text. \"\n",
    "        \"No reasoning. \" # Test-Weise, weil sonst zu lange Zeiten.\n",
    "        \"Output only the diarized transcript.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = (\n",
    "        \"Add speaker labels to the following transcript. \"\n",
    "        \"Use '[Sprecher 1]', '[Sprecher 2]', ... for the different speakers. \"\n",
    "        \"Check thoroughly for every sentence if the assignment to the speaker is contextually and logically plausible. \"\n",
    "        \"Produce a readable dialogue format between Speakers.\\n\\n\"\n",
    "        f\"{transcript}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    return chat_vllm(messages, temperature=0.0, max_tokens=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06fe6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kombinierter Test: Whisper-Diarisierung -> LLM-Diarisierung anhand der Test-Audio, True setzen für Test\n",
    "whisper_llm_test = False\n",
    "if whisper_llm_test:\n",
    "    print(\"Starte Transkription mit faster-whisper\")\n",
    "    t0 = time.time()\n",
    "    transcript, segs, info = transcribe_faster_whisper(TEST_AUDIO, language=\"de\")\n",
    "    t1 = time.time()\n",
    "    print(f\"Whisper-Transkription abgeschlossen in ({t1 - t0:.2f}s)\")\n",
    "    print(\"LLM-Diarisierung gestartet\")\n",
    "    t2 = time.time()\n",
    "    diarized = diarize_with_llm(transcript)\n",
    "    t3 = time.time()\n",
    "    print(f\"LLM-Diarisierung abgeschlossen in ({t3 - t2:.2f}s)\")\n",
    "    print(diarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c3b0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pyannote-Setup (CPU-only)\n",
    "import torch\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "assert HF_TOKEN, \"HUGGINGFACE_TOKEN fehlt in .env\" # Fehlerbehandlung\n",
    "\n",
    "PYANNOTE_MODEL_ID = os.getenv(\"PYANNOTE_MODEL_ID\")\n",
    "\n",
    "_pyannote_pipeline = None\n",
    "\n",
    "def get_pyannote_pipeline():\n",
    "    global _pyannote_pipeline\n",
    "    if _pyannote_pipeline is None:\n",
    "        _pyannote_pipeline = Pipeline.from_pretrained(\n",
    "            PYANNOTE_MODEL_ID,\n",
    "            token=HF_TOKEN\n",
    "        )\n",
    "\n",
    "        # CPU erzwingen\n",
    "        _pyannote_pipeline.to(torch.device(\"cpu\"))\n",
    "    return _pyannote_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daac6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pyannote starten\n",
    "def run_pyannote(wav_path: Path):\n",
    "    pipeline = get_pyannote_pipeline()\n",
    "    \n",
    "    diarization = pipeline(str(wav_path))\n",
    "\n",
    "    return diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b741bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Format-Funktion für Pyannote-Ausgabe\n",
    "def pyannote_to_lines(diarization):\n",
    "    lines = []\n",
    "    for turn, _, speaker in diarization.speaker_diarization.itertracks(yield_label=True):\n",
    "        lines.append(f\"{speaker}\\t{turn.start:.2f}\\t{turn.end:.2f}\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63e8db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisierung abgeschlossen\n",
      "Pyannote gestartet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liegepa/jupyter/diarization-benchmark/.venv/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling.py:103: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1857.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pyannote abgeschlossen in (57.04s)\n",
      "Rohformat:\n",
      "DiarizeOutput(speaker_diarization=<pyannote.core.annotation.Annotation object at 0x7f90f8812a50>, exclusive_speaker_diarization=<pyannote.core.annotation.Annotation object at 0x7f90fa898350>, speaker_embeddings=array([[-0.21349959,  0.07057523,  0.12126339,  0.1573621 ,  0.07819177,\n",
      "        -0.1282401 , -0.14794387, -0.1472371 ,  0.10106144, -0.05143875,\n",
      "        -0.03155115,  0.01284267, -0.08864832,  0.12535502, -0.13084341,\n",
      "         0.02198356, -0.19278218, -0.00095082,  0.10123547,  0.30632917,\n",
      "        -0.10909807, -0.02947721,  0.2894459 ,  0.00421049,  0.096114  ,\n",
      "         0.25439798, -0.17044651, -0.09961392, -0.26644182,  0.03953301,\n",
      "         0.23061309, -0.29840075,  0.03990227,  0.28366442,  0.21552601,\n",
      "        -0.18485279, -0.12113975, -0.336726  , -0.12392942,  0.04880864,\n",
      "         0.05475228, -0.12456403, -0.10887798,  0.08354429,  0.10347382,\n",
      "         0.09185074, -0.14566305,  0.17769727,  0.2132832 ,  0.00486635,\n",
      "        -0.15889333, -0.07557846, -0.11836588, -0.09117792, -0.18161073,\n",
      "         0.04452716, -0.05216162,  0.16807998, -0.01917047,  0.1948501 ,\n",
      "         0.03341585, -0.33279355,  0.08592643, -0.02830752, -0.16979033,\n",
      "         0.24958266, -0.05962302,  0.09844304,  0.0837435 ,  0.04697466,\n",
      "        -0.11175381, -0.13050033,  0.05210767,  0.09744507, -0.46877201,\n",
      "        -0.15041678, -0.05353093,  0.0345008 ,  0.03720512, -0.27015555,\n",
      "         0.03892645,  0.11737566,  0.30600548, -0.18208018, -0.07069323,\n",
      "         0.05168283, -0.09261239, -0.03175257, -0.02207433, -0.34071371,\n",
      "         0.20057947, -0.04909725,  0.25245831,  0.25835165, -0.11000747,\n",
      "        -0.07994201,  0.062123  , -0.04331584,  0.15522485, -0.26424208,\n",
      "         0.04406153,  0.09151666, -0.09546899, -0.07170307,  0.18732982,\n",
      "         0.23078538,  0.15730639,  0.18747292,  0.09671153, -0.43073383,\n",
      "         0.08747329,  0.10252059, -0.22322121,  0.15217367, -0.24058743,\n",
      "        -0.26084567,  0.21354645, -0.0087835 , -0.08565669,  0.09620809,\n",
      "         0.15983626,  0.27424635, -0.02531166, -0.11103767,  0.08705546,\n",
      "         0.42820504, -0.01945991,  0.17184789, -0.09919072, -0.1839753 ,\n",
      "        -0.089159  ,  0.05093684,  0.03971478, -0.00738618,  0.0604382 ,\n",
      "        -0.11591366, -0.02953577, -0.21582192,  0.03878029,  0.06453471,\n",
      "         0.09387534, -0.00914873, -0.07038713, -0.03334719,  0.00824876,\n",
      "         0.32836214, -0.03042274, -0.0557164 , -0.15261784, -0.34421019,\n",
      "        -0.02296201, -0.26018183, -0.06945042,  0.21721003,  0.13724689,\n",
      "        -0.01689607,  0.14640381, -0.2139217 ,  0.15708725,  0.00623349,\n",
      "         0.07216921, -0.07485278, -0.13566762,  0.08067455, -0.21338135,\n",
      "         0.02582701, -0.05771457,  0.1877075 , -0.16616773,  0.01743887,\n",
      "        -0.05419169,  0.0859741 ,  0.05843984, -0.09050719, -0.06405763,\n",
      "         0.16022036,  0.18670911,  0.16148978, -0.03825349,  0.20522716,\n",
      "         0.0462033 , -0.16247979, -0.08262898,  0.19186153,  0.26536204,\n",
      "        -0.0423195 ,  0.06682502, -0.04412629, -0.16947175, -0.07029066,\n",
      "         0.04043832,  0.12663099, -0.00468323, -0.05620073,  0.05930827,\n",
      "         0.21291754,  0.22138261, -0.02921437,  0.10132201,  0.14357708,\n",
      "         0.24210217,  0.10735031,  0.26996607,  0.02134043,  0.04678403,\n",
      "        -0.07143349, -0.19028888,  0.08579499,  0.20214736,  0.22557477,\n",
      "         0.03432438,  0.29737992, -0.00494914,  0.02924097,  0.35935083,\n",
      "        -0.14013593, -0.18680726, -0.19199004, -0.19092562,  0.23803595,\n",
      "         0.17530261,  0.12118154,  0.10488256, -0.2880654 ,  0.02049088,\n",
      "         0.19754417, -0.22250797, -0.07918317,  0.07808154, -0.29513863,\n",
      "         0.13400489, -0.27296618, -0.01309959,  0.01123423, -0.06775017,\n",
      "         0.07379274,  0.03239263, -0.12493729, -0.05478595, -0.19600989,\n",
      "        -0.31768323, -0.16900895, -0.15813203, -0.23138956, -0.19249934,\n",
      "         0.00404564,  0.30905514,  0.05096266,  0.0017904 , -0.13427686,\n",
      "         0.20846113, -0.26285361,  0.19995009,  0.04081204,  0.10609831,\n",
      "         0.10815387],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ]]))\n",
      "Text-Aufbereitung begonnen\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DiarizeOutput' object has no attribute 'itertracks'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(diarization)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mText-Aufbereitung begonnen\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpyannote_to_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiarization\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mpyannote_to_lines\u001b[39m\u001b[34m(diarization)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpyannote_to_lines\u001b[39m(diarization):\n\u001b[32m      3\u001b[39m     lines = []\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m turn, _, speaker \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdiarization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitertracks\u001b[49m(yield_label=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m      5\u001b[39m         lines.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeaker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mturn.start\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mturn.end\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(lines)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DiarizeOutput' object has no attribute 'itertracks'"
     ]
    }
   ],
   "source": [
    "### Pyannote-Test, bei Bedarf auf True setzen\n",
    "pyannote_test = True\n",
    "if pyannote_test:\n",
    "    wav_path = ensure_wav_16k_mono(TEST_AUDIO, CONVERTED_DIR)\n",
    "    print(\"Normalisierung abgeschlossen\")\n",
    "    print(\"Pyannote gestartet...\")\n",
    "    t0 = time.time()\n",
    "    diarization = run_pyannote(wav_path)\n",
    "    t1 = time.time()\n",
    "    print(f\"Pyannote abgeschlossen in ({t1 - t0:.2f}s)\")\n",
    "    print(\"Rohformat:\")\n",
    "    print(diarization)\n",
    "    print(\"Text-Aufbereitung begonnen\")\n",
    "    print(pyannote_to_lines(diarization))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1774b9eb",
   "metadata": {},
   "source": [
    "Batch-Loop für alle Audios\n",
    "- Whisper -> LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b159cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input-Audios vorbereiten\n",
    "from pathlib import Path\n",
    "\n",
    "BATCH_AUDIO_DIR = REPO_ROOT / \"data\" / \"input_audio\"\n",
    "BATCH_EXTS = {\".wav\", \".mp3\", \".m4a\", \".flac\", \".ogg\"}\n",
    "\n",
    "def list_audio_files(folder: Path) -> list[Path]:\n",
    "    files = []\n",
    "    for p in folder.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in BATCH_EXTS:\n",
    "            files.append(p)\n",
    "    return sorted(files)\n",
    "\n",
    "audio_files = list_audio_files(BATCH_AUDIO_DIR)\n",
    "print(\"Found files:\", len(audio_files))\n",
    "for f in audio_files[:10]:\n",
    "    print(\"-\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7078569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Laufzeit - Messung und korrektes Speichern, Hilfsfunktion\n",
    "RESULTS_DIR = REPO_ROOT / \"results\"\n",
    "\n",
    "def save_run(out_dir: Path, *, meta: dict, transcript: str, diarized: str):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (out_dir / \"meta.json\").write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    (out_dir / \"transcript.txt\").write_text(transcript, encoding=\"utf-8\")\n",
    "    (out_dir / \"llm_diarized.txt\").write_text(diarized, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Haupt-Pipeline Batch-LLM-Diarisierung\n",
    "def run_whisper_llm_on_file(audio_path: Path, *, clip_chars: int | None = None) -> dict:\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 1) normalize\n",
    "    wav_path = ensure_wav_16k_mono(audio_path, REPO_ROOT / \"data\" / \"normalised_audio\")\n",
    "\n",
    "    # 2) transcribe\n",
    "    t1 = time.time()\n",
    "    transcript, segs, info = transcribe_faster_whisper(str(wav_path), language=\"de\")\n",
    "    t2 = time.time()\n",
    "\n",
    "    # 3) LLM diarize\n",
    "    diarized = diarize_with_llm(llm_input)\n",
    "    t3 = time.time()\n",
    "\n",
    "    meta = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"audio_path\": str(audio_path),\n",
    "        \"wav_path\": str(wav_path),\n",
    "        \"vllm_base_url\": VLLM_BASE_URL,\n",
    "        \"vllm_model\": VLLM_MODEL,\n",
    "        \"whisper_model_size\": WHISPER_MODEL_SIZE,\n",
    "        \"whisper_device\": WHISPER_DEVICE,\n",
    "        \"whisper_compute_type\": WHISPER_COMPUTE_TYPE,\n",
    "        \"transcript_chars\": len(transcript),\n",
    "        \"transcript_words\": len(transcript.split()),\n",
    "        \"llm_input_chars\": len(llm_input),\n",
    "        \"llm_output_chars\": len(diarized),\n",
    "        \"seconds_total\": round(t3 - t0, 2),\n",
    "        \"seconds_transcribe\": round(t2 - t1, 2),\n",
    "        \"seconds_llm\": round(t3 - t2, 2),\n",
    "        \"language\": getattr(info, \"language\", None),\n",
    "        \"language_probability\": float(getattr(info, \"language_probability\", 0.0) or 0.0),\n",
    "    }\n",
    "\n",
    "    # speichern\n",
    "    out_dir = RESULTS_DIR / audio_path.stem / VLLM_MODEL\n",
    "    save_run(out_dir, meta=meta, transcript=transcript, diarized=diarized)\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0811d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ausführen der Pipeline für alle Audios\n",
    "\n",
    "metas = []\n",
    "failures = []\n",
    "\n",
    "for i, f in enumerate(audio_files, 1):\n",
    "    print(f\"\\n[{i}/{len(audio_files)}] Processing:\", f)\n",
    "    try:\n",
    "        meta = run_whisper_llm_on_file(f, clip_chars=BATCH_CLIP_CHARS)\n",
    "        metas.append(meta)\n",
    "        print(\"  -> OK | total:\", meta[\"seconds_total\"], \"s | llm:\", meta[\"seconds_llm\"], \"s | chars:\", meta[\"transcript_chars\"])\n",
    "    except Exception as e:\n",
    "        failures.append({\"file\": str(f), \"error\": repr(e)})\n",
    "        print(\"  -> FAIL:\", repr(e))\n",
    "\n",
    "# summary files\n",
    "summary_dir = RESULTS_DIR / \"summaries\" / VLLM_MODEL\n",
    "summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "(summary_dir / \"summary_meta.json\").write_text(json.dumps(metas, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "(summary_dir / \"failures.json\").write_text(json.dumps(failures, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "print(\"Success:\", len(metas), \"Failures:\", len(failures))\n",
    "print(\"Summary:\", summary_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
